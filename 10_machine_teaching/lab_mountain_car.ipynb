{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GBod1nv65dN"
   },
   "source": [
    "## Lab: Machine Teaching in the Mountain Car Environment\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: November 29, 2023\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo\n",
    "\n",
    "RLlib seems to be refactored and the book code won't work\n",
    "\n",
    "Instead try this:\n",
    "\n",
    "- Use `gym`\n",
    "- Run experiment without reward shaping\n",
    "- Try the reward shaping on page 322 of book\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krpOsEbE_aTj",
    "tags": []
   },
   "source": [
    "### Goal and Environment\n",
    "\n",
    "From OpenAI `Gym` documentation:\n",
    "\n",
    "\"A car is on a one-dimensional track, positioned between two “mountains”. The goal is to drive up the mountain on the right; however, the car’s engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.\"\n",
    "\n",
    "In the default environment, there is a reward of -1 per time step.  \n",
    "This is intended to prompt the car to reach the goal quickly.  \n",
    "Without additional reward signals, this is not an easy problem to solve.\n",
    "\n",
    "The episode terminates after 200 steps.\n",
    "\n",
    "This is the `gym` environment that we want: `'MountainCar-v0'`\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./mtn_car.png\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Assignment\n",
    "\n",
    "1) Using the `'MountainCar-v0'` environment, show the state space and the action space. Explain what they mean.\n",
    "2) Have the agent take three steps and print the rewards  \n",
    "3) Attempt to run the agent for 250 steps. Print results that verify the episode is done after 200 steps.  \n",
    "4) Apply machine teaching and an RL algorithm to improve agent performance. Show all code and results below.\n",
    "\n",
    "**NOTE:** You might use the code/ideas from the Enes text (Chapter 10 starting on page 320). Note that this code will be dated as the `RLlib` codebase changes rapidly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Code\n",
    "\n",
    "The code can be found in the book [repo](https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python/tree/master/Chapter10).\n",
    "\n",
    "Since there is a fair bit of code, it is not reproduced here.\n",
    "\n",
    "We will download the code and run the files:\n",
    "\n",
    "- `custom_mcar.py`\n",
    "- `mcar_train.py`\n",
    "- `mcar_demo.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is created with this class from `custom_mcar.py` (partially shown here):\n",
    "\n",
    "```\n",
    "class MountainCar(gym.Env):\n",
    "    def __init__(self, env_config={}):\n",
    "        self.wrapped = gym.make(\"MountainCar-v0\")\n",
    "        self.action_space = self.wrapped.action_space\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/abedi756/car-mountain-rainforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "Action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "env.reset()\n",
    "\n",
    "print('State space:', env.observation_space)\n",
    "print('Action space:', env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rOaGhKK7mHg"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 1** [UPDATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_61H87rA_MT"
   },
   "source": [
    "---  \n",
    "\n",
    "### Wrapup\n",
    "\n",
    "UPDATE\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
