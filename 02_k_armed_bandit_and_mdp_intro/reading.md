## Reading

- Sutton & Barto. Chapter 2: Multi-armed Bandits.  
Read through 2.7 Upper-Confidence-Bound Action Selection.

- Sutton & Barto. Chapter 3: Finite Markov Decision Processes
