
## INTRODUCTION TO THE MODULE

This module begins with the k-armed bandit problem, which uses a single state. Even in this simple setup, many fundamental ideas of RL are covered. Next, we study Markov Decision Processes, which provide an important mathematical framework for RL problems. We learn the Bellman equation which helps identify optimality.

## LEARNING OUTCOMES

At the conclusion of this module, you should be able to:

- Understand the k-armed bandit problem
- Simulate a k-armed bandit problem with ùúñ-greedy actions
- Understand how using ùúñ-greedy actions can improve the policy
- Understand the properties of Markov Decision Processes
- Describe the gains process and the agent's objective in RL
- Explain optimal policy and value functions
- Understand how the Bellman equation works
